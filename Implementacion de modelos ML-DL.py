# -*- coding: utf-8 -*-
"""Modelos Total con reps.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tz6tc35NGnc7gLhPpJtrQWkyPHnx5CHn
"""

pip install shap

from google.colab import files
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.graphics.api import interaction_plot,abline_plot
import shap
warnings.filterwarnings("ignore")

"""Importando la data"""

data = pd.read_csv("/content/inputdata.csv",index_col=0)

"""Encoding Binario para la data categórica"""

from sklearn.preprocessing import LabelEncoder
data["CULTIVO"] = LabelEncoder().fit_transform(data["CULTIVO"])

data = data[["LATITUD","LONGITUD","ASNM","CULTIVO","DIRECCION_VIENTO","HUMEDAD","PRECIPITACION","PRESION_ATMOSFERICA","TEMPERATURA","TEMPERATURA_MAXIMA","TEMPERATURA_MINIMA","VELOCIDAD_VIENTO","AREA SEMBRADA (HA)","AREA COSECHADA (HA)","PRODUCCION (T)","RENDIMIENTO CALCULADO (T/HA)"]]

"""Descripción del dataset"""

#Dimensión del dataset
print("Shape del dataset",np.shape(data))

#Resumen de estadísticas del dataset
data.describe()

# BoxPlots del datatset
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

fig, axs = plt.subplots(ncols=4, nrows=4, figsize=(20, 15))
index = 0
axs = axs.flatten()
for k,v in data.items():
    sns.boxplot(y=k, data=data, ax=axs[index])
    index += 1
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)

# Detectando Outliers utilizando el rango intercuartílico
for k, v in data.items():
        q1 = v.quantile(0.25)
        q3 = v.quantile(0.75)
        irq = q3 - q1
        v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]
        perc = np.shape(v_col)[0] * 100.0 / np.shape(data)[0]
        print("Columna %s outliers = %.2f%%" % (k, perc))

# Graficando las distribuciones de probabilidad del datatset
fig, axs = plt.subplots(ncols=4, nrows=4, figsize=(20, 20))
index = 0
axs = axs.flatten()
for k,v in data.items():
    sns.distplot(v, ax=axs[index])
    index += 1
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)

"""Los gráficos de histogramas muestran que las columnas HUMEDAD, PRECIPITACION, VELOCIDAD VIENTO tienen distribuciones altamente sesgadas. Las variables AREA COSECHADA (HA) Y PRODUCCION (T) siguen la misma distribución de probabilidad que la variable AREA SEMBRADA lo cual sugiere a priori una alta correlación entre las variables. El RENDIMIENTO (T/HA) parece seguir una distribución normal; otras columnas parecen seguir una distribución normal o multimodal excepto CULTIVO, la cual es una variables binaria."""

# Correlación por pares de datos de la totalidad del dataset
plt.figure(figsize=(20, 10))
sns.heatmap(data.corr().abs(),annot=True)

"""**Implementación de modelos**

***División del conjunto de datos en Entrenamiento, Validación y Prueba***
"""

import sklearn
from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error 
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Definiendo el dataset de entrada para los modelos
data = data[["LATITUD","LONGITUD","ASNM","CULTIVO","DIRECCION_VIENTO","HUMEDAD","PRECIPITACION","PRESION_ATMOSFERICA","TEMPERATURA","TEMPERATURA_MAXIMA","TEMPERATURA_MINIMA","VELOCIDAD_VIENTO","AREA SEMBRADA (HA)","RENDIMIENTO CALCULADO (T/HA)"]]
columns = data.drop("RENDIMIENTO CALCULADO (T/HA)",axis=1)

# División del dataset y escalado de datos
X = data.iloc[:, 0:13].values
Y = data.iloc[:, 13].values.reshape(-1,1)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 25) #podemos setear el random state a 0
sc_X = StandardScaler()
sc_y = StandardScaler() 
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.fit_transform(X_test) 
print("Shape of X_train: ",X_train.shape)
print("Shape of X_test: ", X_test.shape)
print("Shape of Y_train: ",Y_train.shape)
print("Shape of Y_test",Y_test.shape)

"""***Análisis y Reducción de la Dimensionalidad del dataset seleccionado***

***Análisis de Correlaciones***
"""

# Correlación por pares de datos del dataset seleccionado
plt.figure(figsize=(20, 10))
sns.heatmap(data.corr().abs(),annot=True)

"""***Multicolinealidad***"""

# Análisis del VIF para identificar posibles relaciones de dependencia en las variables independientes del conjunto de datos de entrenamiento
from statsmodels.stats.outliers_influence import variance_inflation_factor
X = data.iloc[:, 0:13]
vif_data = pd.DataFrame() 
vif_data["Feature"] =X.columns 
vif_data["VIF"] = [variance_inflation_factor(X_train, i) 
                          for i in range(len(X.columns))] 
vif_data

"""***Análisis de características significativas usando Backward Elimination***"""

!pip install mlxtend
import joblib
import sys
sys.modules['sklearn.externals.joblib'] = joblib
from mlxtend.feature_selection import SequentialFeatureSelector as SFS

# Utilizando un algoritmo de Randoom Forest para encontrar la mejor combinación de variables
from sklearn.ensemble import RandomForestRegressor
sfs = SFS(RandomForestRegressor(n_jobs=-1,random_state=0), 
          k_features=(1,13), 
          forward=True, 
          floating=False, 
          scoring='r2',
          cv=5,
          )
sfs = sfs.fit(X_train,Y_train)

print('\nCaracterísticas Significativas (índice en el dataframe):')
print(sfs.k_feature_idx_)
print('CV Score:')
print(sfs.k_score_)

data.columns

"""La técnica Backward elimination sugiere que las características significativas son la longitud, la altura sobre el nivel del mar, el tipo de cultivo, la dirección del viento, la precipitación acumulada, la temperatura media y el área sembrada.

***Análisis de características significativas usando Sequential Forward Selection***
"""

# Graficando el aporte de las carcaterísticas al performance del modelo, conforme se añade una a una
from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs
fig1 = plot_sfs(sfs.get_metric_dict(), kind='std_dev')
plt.title('Sequential Forward Selection (w. StdDev)')
plt.grid()
plt.xlabel("Número de características")
plt.ylabel("Performance")
plt.title("Sequential Forward Selection (w.StdDev)")
plt.show()

"""Con 7 características significativas nuestro modelo alcanzaría su mejor desempeño, sin embargo, al utilizar la totalidad de características el modelo continúa presentando buen desempeño.

**Modelos de Machine Learning**

***Regresión Lineal***
"""

from sklearn.linear_model import LinearRegression
regressor_linear = LinearRegression(fit_intercept=True,n_jobs=-1).fit(X_train, Y_train)

CV = []
R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    # Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = LinearRegression(fit_intercept=True,n_jobs=-1).fit(X_train, Y_train)

    # Cross Validation Score
    cv_regressor = cross_val_score(estimator = regressor, X = X_train, y = Y_train, cv = 5)

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
    CV.append(cv_regressor.mean())
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

# Guardando las repeticiones en un pandas dataframe
metricslr=pd.DataFrame({'cv_lr':CV,
                        'r2_score_lr_train':R2train,
                        'r2_score_lr_test':R2test,
                        'mse_lr':MSE,
                        'rmse_lr':RMSE,
                        'mae_lr':MAE})
metricslr

# Exportando las repeticiones
metricslr.to_csv('repeticiones regresion lineal.csv', encoding = 'utf-8-sig') 
files.download('repeticiones regresion lineal.csv')

print("Mejor R2 test: %.4f" % (r2_score(obs,pred)))

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión Regresión Lineal")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos Regresión Lineal")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales Regresión Lineal")
plt.show()

# Shap Values
explainer = shap.Explainer(regressor, masker=shap.maskers.Impute(data=X_Test),
                            algorithm="linear")
shap_values = explainer(X_Test)
shap.plots.bar(shap_values)
shap.summary_plot(shap_values,plot_type='violin',feature_names=columns.columns)

"""**Decission Tree**"""

from sklearn.tree import DecisionTreeRegressor
regressor_dt = DecisionTreeRegressor(random_state = 0)

# Encontrando los mejores hiperparámetros para el modelo
# param_grid = { 'min_samples_split':[6,8,10,12],
#               'max_depth'  : [1,10,20],
#               'max_features': ['auto', 'log2','sqrt'], 
#               'max_leaf_nodes': [1,10,20],
#               }
# g_search = GridSearchCV(estimator =regressor_dt, param_grid = param_grid, cv = 5, n_jobs = 1, verbose = 0, scoring = "r2")
# g_search.fit(X_train, Y_train);
# print("Los mejores parámetros son: ","\n", g_search.best_params_)

CV = []
R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = DecisionTreeRegressor(criterion = "squared_error", max_depth = 10, max_features= "auto",max_leaf_nodes=10, min_samples_split=6,random_state = 0).fit(X_train, Y_train)

    #  Cross Validation Score
    cv_regressor = cross_val_score(estimator = regressor, X = X_train, y = Y_train, cv = 5)

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
    CV.append(cv_regressor.mean())
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

# Guardando las repeticiones en un pandas dataframe
metricsdt=pd.DataFrame({'cv_dt':CV,
                        'r2_score_dt_train':R2train,
                        'r2_score_dt_test':R2test,
                        'mse_dt':MSE,
                        'rmse_dt':RMSE,
                        'mae_dt':MAE})
metricsdt

# Exportando las repeticiones
metricslr.to_csv('repeticiones arbol de decision.csv', encoding = 'utf-8-sig') 
files.download('repeticiones arbol de decision.csv')

print("Mejor R2 test: %.4f" % (r2_score(obs,pred)))

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión ")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos Árbol de decisión")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales Árbol de Decisión")
plt.show()

# Shap Values
explainer = shap.TreeExplainer(regressor, X_test)
shap_values = explainer(X_test)
shap.plots.bar(shap_values)
shap.summary_plot(shap_values, X_test, plot_type='violin',feature_names=columns.columns)

"""**Extreme Gradient Boosting Regressor**"""

from sklearn.ensemble import GradientBoostingRegressor
regressor_xgbr=GradientBoostingRegressor(random_state=0)

# Encontrando los mejores hiperparámetros para el modelo
# param_grid = {'min_samples_split':[2,4,6,8,10],
#               'max_depth'  : [1,10,100,500,1000],
#               'max_features': ['auto', 'log2','sqrt'], 
#               'max_leaf_nodes': [1,10,100,500,1000],
#               'n_estimators': [20,50,100,150],
#               }
# g_search = GridSearchCV(estimator =regressor_xgbr, param_grid = param_grid, cv = 5, n_jobs = 1, verbose = 0, scoring = "r2")
# g_search.fit(X_train, Y_train);
# print("Los mejores parámetros son: ","\n", g_search.best_params_)

CV = []
R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = GradientBoostingRegressor(n_estimators = 50, min_samples_split= 2, max_depth = 10, max_features= 'log2', max_leaf_nodes = 100, random_state = 0).fit(X_train , Y_train)

    #  Cross Validation Score
    cv_regressor = cross_val_score(estimator = regressor, X = X_train, y = Y_train, cv = 5)

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
    CV.append(cv_regressor.mean())
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

# Guardando las repeticiones en un pandas dataframe
metricsxgbr=pd.DataFrame({'cv_xgbr':CV,
                        'r2_score_xgbr_train':R2train,
                        'r2_score_xgbr_test':R2test,
                        'mse_xgbr':MSE,
                        'rmse_xgbr':RMSE,
                        'mae_xgbr':MAE})
metricsxgbr

# Exportando las repeticiones
metricsxgbr.to_csv('repeticiones XGBoost.csv', encoding = 'utf-8-sig') 
files.download('repeticiones XGBoost.csv')

print("Mejor R2 test: %.4f" % (r2_score(obs,pred)))

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión ")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos XGBoost")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales XGBoost")
plt.show()

# Shap Values
explainer = shap.TreeExplainer(regressor, X_test)
shap_values = explainer(X_test)
shap.plots.bar(shap_values)
shap.summary_plot(shap_values, X_test, plot_type='violin',feature_names=columns.columns)

"""**Random Forest**"""

from sklearn.ensemble import RandomForestRegressor
regressor_rf = RandomForestRegressor(random_state = 0)

# Encontrando los mejores hiperparámetros para el modelo
# param_grid = {'min_samples_split':[2,4,6,8,10],
#               'max_depth'  : [1,10,100,500,1000],
#               'max_features': ['auto', 'log2','sqrt'], 
#               'max_leaf_nodes': [1,10,100,500,1000],
#               'n_estimators': [300,500,800,1000],
#               }
# g_search = GridSearchCV(estimator =regressor_rf, param_grid = param_grid, cv = 5, n_jobs = 1, verbose = 0, scoring = "r2")
# g_search.fit(X_train, Y_train);
# print("Los mejores parámetros son: ","\n", g_search.best_params_)

CV = []
R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = RandomForestRegressor(n_estimators = 500, min_samples_split= 2, max_depth = 100, max_features= 'log2', max_leaf_nodes = 1000, random_state = 0).fit(X_train, Y_train)

    #  Cross Validation Score
    cv_regressor = cross_val_score(estimator = regressor, X = X_train, y = Y_train, cv = 5)

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
    CV.append(cv_regressor.mean())
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

# Guardando las repeticiones en un pandas dataframe
metricsrf=pd.DataFrame({'cv_rf':CV,
                        'r2_score_rf_train':R2train,
                        'r2_score_rf_test':R2test,
                        'mse_rf':MSE,
                        'rmse_rf':RMSE,
                        'mae_rf':MAE})
metricsrf

metricsrf.to_csv('repeticiones random forest.csv', encoding = 'utf-8-sig') 
files.download('repeticiones random forest.csv')

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión Bosques Aleatorios")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos Bosques Aleatorios")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales Bosques Aleatorios")
plt.show()

# Shap Values
explainer = shap.TreeExplainer(regressor, X_test)
shap_values = explainer(X_test)
shap.plots.bar(shap_values)
shap.summary_plot(shap_values, X_test, plot_type='violin',feature_names=columns.columns)

"""Support Vector Regression"""

from sklearn.svm import SVR
regressor_svr = SVR()

#Encontrando los mejores hiperparámetros para el modelo
# param_grid = { 'kernel':['linear','rbf','sigmoid'],
#               'gamma': ['scale', 'auto'], 
#               'C': [0.01,0.1,1.0,10,100,1000],
#               }
# g_search = GridSearchCV(estimator =regressor_svr, param_grid = param_grid, cv = 5, n_jobs = 1, verbose = 0, scoring = "r2")
# g_search.fit(X_train, Y_train);
# print("Los mejores parámetros son: ","\n", g_search.best_params_)

CV = []
R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = SVR(kernel="rbf", gamma ="auto", C=1).fit(X_train, Y_train)

    #  Cross Validation Score
    cv_regressor = cross_val_score(estimator = regressor, X = X_train, y = Y_train, cv = 5)

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
    CV.append(cv_regressor.mean())
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

# Guardando las repeticiones en un pandas dataframe
metricssvr=pd.DataFrame({'cv_svr':CV,
                        'r2_score_svr_train':R2train,
                        'r2_score_svr_test':R2test,
                        'mse_svr':MSE,
                        'rmse_svr':RMSE,
                        'mae_svr':MAE})
metricssvr

metricssvr.to_csv('repeticiones svr.csv', encoding = 'utf-8-sig') 
files.download('repeticiones svr.csv')

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión Máquinas de Soporte Vectorial")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos Máquinas de Soporte Vectorial")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales Máquinas de Soporte Vectorial")
plt.show()

# Shap Values
explainer = shap.Explainer(regressor.predict, X_test)
shap_values = explainer(X_test)
shap.plots.bar(shap_values)
shap.summary_plot(shap_values, X_test, plot_type='violin',feature_names=columns.columns)

"""**Deep Learning Models**"""

import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from keras.callbacks import EarlyStopping
from keras.layers import Dropout
from keras.layers import BatchNormalization

"""***Multilayer Perceptron***"""

with tf.device('/device:GPU:0'):
    model1 = Sequential()
    model1.add(Dense(128,input_dim=13,activation='sigmoid'))
    model1.add(Dense(64, activation='relu'))
    model1.add(Dense(30,activation='relu'))
    model1.add(Dense(20,activation='relu'))
    model1.add(Dense(5,activation='relu'))
    model1.add(Dense(5,activation='relu'))
    model1.add(Dense(10,activation='relu'))
    model1.add(Dense(15,activation='relu'))
    model1.add(Dense(5,activation='relu'))
    model1.add(Dense(1,activation='linear'))
    model1.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])
    model1.summary()
    history = model1.fit(X_train,Y_train,epochs=150,validation_split=0.2,batch_size=220, verbose=1, shuffle=False)
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(1,len(loss)+1)
    plt.plot(epochs,loss,'y',label='Training loss')
    plt.plot(epochs,val_loss,'r',label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

    acc = history.history['mae']
    val_acc = history.history['val_mae']
    plt.plot(epochs,acc,'y',label='Training MAE')
    plt.plot(epochs,val_acc,'r',label='Validation MAE')
    plt.title('Training and validation MAE')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = model1

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
    
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

CV = []
for i in range(10):
    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 
    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    with tf.device('/device:GPU:0'):
      def create_network():
        model1 = Sequential()
        model1.add(Dense(128,input_dim=13,activation='sigmoid'))
        model1.add(Dense(64, activation='relu'))
        model1.add(Dense(30,activation='relu'))
        model1.add(Dense(20,activation='relu'))
        model1.add(Dense(5,activation='relu'))
        model1.add(Dense(5,activation='relu'))
        model1.add(Dense(10,activation='relu'))
        model1.add(Dense(15,activation='relu'))
        model1.add(Dense(5,activation='relu'))
        model1.add(Dense(1,activation='linear'))
        model1.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])
        return model1
    # Envolver el modelo de Keras para que pueda ser utilizado por Sklearn
    neural_network = KerasRegressor(build_fn= create_network,epochs=150,validation_split=0.2) 
    # Cross Validation Score
    cv_regressor =cross_val_score(neural_network, X = X_train, y = Y_train, cv = 5,scoring='r2',n_jobs=1)
    CV.append(cv_regressor.mean())

# Guardando las repeticiones en un pandas dataframe
metricsmlp=pd.DataFrame({'cv_mlp':CV,
                        'r2_score_mlp_train':R2train,
                        'r2_score_mlp_test':R2test,
                        'mse_mlp':MSE,
                        'rmse_mlp':RMSE,
                        'mae_mlp':MAE})
metricsmlp

metricsmlp.to_csv('repeticiones mlp.csv', encoding = 'utf-8-sig') 
files.download('repeticiones mlp.csv')

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos Perceptrón Multicapa")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales Perceptrón Multicapa")
plt.show()

# Shap Values
explainer = shap.Explainer(model1.predict, X_test)
shap_values = explainer(X_test)
shap.plots.bar(shap_values)
shap.summary_plot(shap_values, X_test, plot_type='violin',feature_names=columns.columns)

"""**Recurrent Neural Network: Long Short Term Memory (LSTM)**"""

X_train=X_train.reshape(1197,1,13)
Y_train=Y_train.reshape(1197,1,1)
X_test=X_test.reshape(300,1,13)
Y_test=Y_test.reshape(300,1,1)

from keras.layers import LSTM
with tf.device('/device:GPU:0'):
  model = Sequential()
  model.add(LSTM(10,input_shape=(1,13),return_sequences=True, activation='relu'))
  model.add(Dense(5,activation='relu'))
  model.add(LSTM(10,activation='relu'))
  model.add(Dense(5,activation='relu'))
  model.add(Dense(10,activation='relu'))
  model.add(Dense(1))
  model.compile(optimizer="Adam", loss="mse",metrics=["mae"])
  model.summary()
  history = model.fit(X_train,Y_train,validation_split=0.2,epochs=150, batch_size=220, verbose=1, shuffle=False)
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  epochs = range(1,len(loss)+1)
  plt.plot(epochs,loss,'y',label='Training loss')
  plt.plot(epochs,val_loss,'r',label='Validation loss')
  plt.title('Training and validation loss')
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.legend()
  plt.show()

  acc = history.history['mae']
  val_acc = history.history['val_mae']
  plt.plot(epochs,acc,'y',label='Training MAE')
  plt.plot(epochs,val_acc,'r',label='Validation MAE')
  plt.title('Training and validation MAE')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.show()

R2train = []
R2test = []
MSE = []
RMSE = []
MAE = []
pred=np.array(0)
obs=np.array(0)

for i in range(10):

    # Train, Test, Split
    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20) 

    sc_X = StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.fit_transform(X_test)     
    
    X_train=X_train.reshape(1197,1,13)
    Y_train=Y_train.reshape(1197,1,1)
    X_test=X_test.reshape(300,1,13)
    Y_test=Y_test.reshape(300,1,1)

    #Llamamos nuestra función regresora con los mejores hiperparámetros
    regressor = model

    # Predicting R2 Score the Train set results
    y_pred_regressor_train = regressor.predict(X_train).reshape(1197,1)
    Y_train=Y_train.reshape(1197,1)
    r2_score_regressor_train = r2_score(Y_train, y_pred_regressor_train)

    # Predicting R2 Score the Test set results
    y_pred_regressor_test = regressor.predict(X_test).reshape(300,1)
    Y_test=Y_test.reshape(300,1)
    r2_score_regressor_test = r2_score(Y_test, y_pred_regressor_test)

    # Predicting MSE the Test set results
    mse_regressor = mean_squared_error(Y_test, y_pred_regressor_test)

    # Predicting RMSE the Test set results
    rmse_regressor = mean_squared_error(Y_test, y_pred_regressor_test, squared=False)

    # Predicting MAE the Test set results
    mae_regressor = mean_absolute_error(Y_test, y_pred_regressor_test)
            
   
    R2train.append(r2_score_regressor_train)
    R2test.append(r2_score_regressor_test)
    MSE.append(mse_regressor)
    RMSE.append(rmse_regressor)
    MAE.append(mae_regressor)
    
    if r2_score_regressor_test.mean() >= max(R2test):
        pred =  regressor.predict(X_test)
        obs = Y_test
        X_Test = X_test
        Y_Test = Y_test
        model =  regressor

CV = []
for i in range(10): 
    #Llamamos nuestra función regresora con los mejores hiperparámetros
    with tf.device('/device:GPU:0'):
      def rnn_model():
        model = Sequential()
        model.add(LSTM(10,input_shape=(1,13),return_sequences=True, activation='relu'))
        model.add(Dense(5,activation='relu'))
        model.add(LSTM(10,activation='relu'))
        model.add(Dense(5,activation='relu'))
        model.add(Dense(10,activation='relu'))
        model.add(Dense(1))
        model.compile(optimizer="Adam", loss="mse",metrics=["mae"])
        return model
    # Envolver el modelo de Keras para que pueda ser utilizado por Sklearn
    rnn_network = KerasRegressor(build_fn= rnn_model,validation_split=0.2,batch_size=220,epochs=150, verbose=1, shuffle=False)
    # Cross Validation Score
    cv_regressor =cross_val_score(rnn_network, X = X_train, y = Y_train, cv = 5,scoring='r2',n_jobs=1)
    CV.append(cv_regressor.mean())

# Guardando las 100 repeticiones en un pandas dataframe
metricslstm=pd.DataFrame({'cv_lstm':CV,
                        'r2_score_lstm_train':R2train,
                        'r2_score_lstm_test':R2test,
                        'mse_lstm':MSE,
                        'rmse_lstm':RMSE,
                        'mae_lstm':MAE})
metricslstm

metricslstm.to_csv('repeticiones lstm.csv', encoding = 'utf-8-sig') 
files.download('repeticiones lstm.csv')

obs,pred = np.array(obs).flatten(), np.array(pred).flatten() 
plt.figure("Diagrama de dispersión")
fig,ax=plt.subplots()
ax.scatter(pred,obs,s=100,alpha=0.3,c="b")
line_fit=sm.OLS(obs,sm.add_constant(pred,prepend=True)).fit()
abline_plot(model_results=line_fit,ax=ax,c="b")
plt.xlabel("Valor Pronosticado")
plt.ylabel("Valor Observado")
plt.title("Gráfico de dispersión de pronósticos Red Neuronal LSTM")
plt.legend()
plt.show()

sns.residplot(obs,pred)
plt.xlabel("Valor Pronosticado")
plt.ylabel("Residuo")
plt.title("Gráfico de residuales Red Neuronal LSTM")
plt.show()

"""**Comparación de modelos**

***Valores promedio de las repeticiones por modelo***
"""

# DataFrame valores promedio de las repeticiones
modelsmean = [('Linear Regression',metricslr['mae_lr'].mean(), metricslr['mse_lr'].mean(), metricslr['rmse_lr'].mean(), metricslr['r2_score_lr_train'].mean(), metricslr['r2_score_lr_test'].mean(), metricslr['cv_lr'].mean()),
          ('Decision Tree',metricsdt['mae_dt'].mean(), metricsdt['mse_dt'].mean(), metricsdt['rmse_dt'].mean(), metricsdt['r2_score_dt_train'].mean(), metricsdt['r2_score_dt_test'].mean(), metricsdt['cv_dt'].mean()),
          ('Support Vector Regression',metricssvr['mae_svr'].mean(), metricssvr['mse_svr'].mean(), metricssvr['rmse_svr'].mean(), metricssvr['r2_score_svr_train'].mean(), metricssvr['r2_score_svr_test'].mean(), metricssvr['cv_svr'].mean()),
          ('XGBoost',metricsxgbr['mae_xgbr'].mean(), metricsxgbr['mse_xgbr'].mean(), metricsxgbr['rmse_xgbr'].mean(), metricsxgbr['r2_score_xgbr_train'].mean(), metricsxgbr['r2_score_xgbr_test'].mean(), metricsxgbr['cv_xgbr'].mean()), 
          ('Random Forest',metricsrf['mae_rf'].mean(), metricsrf['mse_rf'].mean(), metricsrf['rmse_rf'].mean(), metricsrf['r2_score_rf_train'].mean(), metricsrf['r2_score_rf_test'].mean(), metricsrf['cv_rf'].mean()),
          ('Multilayer Perceptron',metricsmlp['mae_mlp'].mean(), metricsmlp['mse_mlp'].mean(), metricsmlp['rmse_mlp'].mean(), metricsmlp['r2_score_mlp_train'].mean(), metricsmlp['r2_score_mlp_test'].mean(), metricsmlp['cv_mlp'].mean()),
          ('LSTM Recurrent Network',metricslstm['mae_lstm'].mean(), metricslstm['mse_lstm'].mean(), metricslstm['rmse_lstm'].mean(), metricslstm['r2_score_lstm_train'].mean(), metricslstm['r2_score_lstm_test'].mean(), metricslstm['cv_lstm'].mean()),
          ]
predictmean = pd.DataFrame(data = modelsmean, columns=['Model','MAE','MSE', 'RMSE', 'R2 (train)', 'R2 (test)', 'Cross-Validation'])
predictmean

"""***Desviación estándar de las repeticiones por modelo***"""

# DataFrame desviación estándar de las repeticiones
modelsdesvest = [('Linear Regression',metricslr['mae_lr'].std(), metricslr['mse_lr'].std(), metricslr['rmse_lr'].std(), metricslr['r2_score_lr_train'].std(), metricslr['r2_score_lr_test'].std(), metricslr['cv_lr'].std()),
                ('Decision Tree',metricsdt['mae_dt'].std(), metricsdt['mse_dt'].std(), metricsdt['rmse_dt'].std(), metricsdt['r2_score_dt_train'].std(), metricsdt['r2_score_dt_test'].std(), metricsdt['cv_dt'].std()),
                ('Support Vector Regression',metricssvr['mae_svr'].std(), metricssvr['mse_svr'].std(), metricssvr['rmse_svr'].std(), metricssvr['r2_score_svr_train'].std(), metricssvr['r2_score_svr_test'].std(), metricssvr['cv_svr'].std()),
                ('XGBoost',metricsxgbr['mae_xgbr'].std(), metricsxgbr['mse_xgbr'].std(), metricsxgbr['rmse_xgbr'].std(), metricsxgbr['r2_score_xgbr_train'].std(), metricsxgbr['r2_score_xgbr_test'].std(), metricsxgbr['cv_xgbr'].std()), 
                ('Random Forest',metricsrf['mae_rf'].std(), metricsrf['mse_rf'].std(), metricsrf['rmse_rf'].std(), metricsrf['r2_score_rf_train'].std(), metricsrf['r2_score_rf_test'].std(), metricsrf['cv_rf'].std()),
                ('Multilayer Perceptron',metricsmlp['mae_mlp'].std(), metricsmlp['mse_mlp'].std(), metricsmlp['rmse_mlp'].std(), metricsmlp['r2_score_mlp_train'].std(), metricsmlp['r2_score_mlp_test'].std(), metricsmlp['cv_mlp'].std()),
                ('LSTM Recurrent Network',metricslstm['mae_lstm'].std(), metricslstm['mse_lstm'].std(), metricslstm['rmse_lstm'].std(), metricslstm['r2_score_lstm_train'].std(), metricslstm['r2_score_lstm_test'].std(), metricslstm['cv_lstm'].std()),
                ]
predictdesvest = pd.DataFrame(data = modelsdesvest, columns=['Model','MAE','MSE', 'RMSE', 'R2 (train)', 'R2 (test)', 'Cross-Validation'])
predictdesvest

"""***Gráficos validación cruzada promedio de las repeticiones por modelo***"""

f, axe = plt.subplots(1,1, figsize=(18,6))
predictmean.sort_values(by=['Cross-Validation'], ascending=False, inplace=True)
sns.barplot(x='Cross-Validation', y='Model', data = predictmean, ax = axe)
axe.set_xlabel('Cross-Validaton Score', size=16)
axe.set_ylabel('Model')
axe.set_xlim(0,1.0)
plt.show()

"""***Gráficos R2 train y test promedio de las repeticiones por modelo***"""

f, axes = plt.subplots(2,1, figsize=(14,10))

predictmean.sort_values(by=['R2 (train)'], ascending=False, inplace=True)

sns.barplot(x='R2 (train)', y='Model', data = predictmean, palette='Blues_d', ax = axes[0])
#axes[0].set(xlabel='Region', ylabel='Charges')
axes[0].set_xlabel('R2 (train)', size=16)
axes[0].set_ylabel('Model')
axes[0].set_xlim(0,1.0)

predictmean.sort_values(by=['R2 (test)'], ascending=False, inplace=True)

sns.barplot(x='R2 (test)', y='Model', data = predictmean, palette='Reds_d', ax = axes[1])
#axes[0].set(xlabel='Region', ylabel='Charges')
axes[1].set_xlabel('R2 (test)', size=16)
axes[1].set_ylabel('Model')
axes[1].set_xlim(0,1.0)

plt.show()

"""***ANOVA Cross Validation Score***"""

# Primero se comprueba que el aprendizaje de los modelos siga un comportamiento normal (en la validación cruzada)
from scipy.stats import shapiro
my_data = [metricslr["cv_lr"],metricsdt["cv_dt"],metricssvr["cv_svr"],metricsxgbr["cv_xgbr"],metricsrf["cv_rf"],metricsmlp["cv_mlp"],metricslstm["cv_lstm"]]
nombres = ["LR","DT","SVR","XGBR","RF","MLP","LSTM"]
pos=0
for i in my_data:
  print(nombres[pos],shapiro(i))
  pos=pos+1

# Los gráficos de boxplot también permitirán ver diferencias entre la distribución de las 100 repeticiones en la validación cruzada (entrenamiento)
models_cv = pd.DataFrame.from_dict({'LR': metricslr.cv_lr, 'DT': metricsdt.cv_dt,'SVR': metricssvr.cv_svr,'XGB': metricsxgbr.cv_xgbr,'RF': metricsrf.cv_rf,'MLP': metricsmlp.cv_mlp,'LSTM': metricslstm.cv_lstm}).melt()
models_cv=models_cv.rename(columns={"variable":"Modelo"})
sns.boxplot(x="Modelo", y="value",data=models_cv)
plt.xlabel("Model")
plt.ylabel("Cross-Validation")
plt.title("Boxplot Cross-Validation Score")
plt.show()

# Aplicamos un test ANOVA para validar si existen diferencias significativas en el aprendizaje, es decir, si existen diferencias significativas entre la capacidad de generalización entre modelos
modelo = ols("value  ~ C(Modelo)", data=models_cv).fit()
anova = sm.stats.anova_lm(modelo)
print(anova)

"""***Gráficos RMSE promedio de las repeticiones***"""

predictmean.sort_values(by=['RMSE'], ascending=False, inplace=True)
f, axe = plt.subplots(1,1, figsize=(18,6))
sns.barplot(x='Model', y='RMSE', data=predictmean, ax = axe)
axe.set_xlabel('Model', size=16)
axe.set_ylabel('RMSE', size=16)
plt.show()

"""***Gráficos MSE promedio de las repeticiones***"""

predictmean.sort_values(by=['MSE'], ascending=False, inplace=True)
f, axe = plt.subplots(1,1, figsize=(18,6))
sns.barplot(x='Model', y='MSE', data=predictmean, ax = axe)
axe.set_xlabel('Model', size=16)
axe.set_ylabel('MSE', size=16)
plt.show()

"""***Gráficos MAE promedio de las repeticiones***"""

predictmean.sort_values(by=['MAE'], ascending=False, inplace=True)
f, axe = plt.subplots(1,1, figsize=(18,6))
sns.barplot(x='Model', y='MAE', data=predictmean, ax = axe)
axe.set_xlabel('Model', size=16)
axe.set_ylabel('MAE', size=16)
plt.show()

"""**Normalidad e intervalos de confianza para el ajuste y el error**

***Test de normalidad Normalidad para el ajuste en el conjunto de datos de prueba***
"""

from scipy.stats import shapiro
my_data = [metricslr["r2_score_lr_test"],metricsdt["r2_score_dt_test"],metricssvr["r2_score_svr_test"],metricsxgbr["r2_score_xgbr_test"],metricsrf["r2_score_rf_test"],metricsmlp["r2_score_mlp_test"],metricslstm["r2_score_lstm_test"]]
nombres = ["LR","DT","SVR","XGBR","RF","MLP","LSTM"]
pos=0
for i in my_data:
  print(nombres[pos],shapiro(i))
  pos=pos+1

"""***Intervalos de confianza para el ajuste en el conjunto de datos de prueba***"""

import scipy.stats as st
my_data = [metricslr["r2_score_lr_test"],metricsdt["r2_score_dt_test"],metricssvr["r2_score_svr_test"],metricsxgbr["r2_score_xgbr_test"],metricsrf["r2_score_rf_test"],metricsmlp["r2_score_mlp_test"],metricslstm["r2_score_lstm_test"]]
nombres = ["LR","DT","SVR","XGBR","RF","MLP","LSTM"]
pos=0
for i in my_data:
  print(nombres[pos],st.t.interval(alpha=0.95, df=len(i)-1, loc=np.mean(i), scale=st.sem(i)))
  pos=pos+1

"""***Test de normalidad Normalidad para el error***"""

from scipy.stats import shapiro
my_data = [metricslr["mse_lr"],metricsdt["mse_dt"],metricssvr["mse_svr"],metricsxgbr["mse_xgbr"],metricsrf["mse_rf"],metricsmlp["mse_mlp"],metricslstm["mse_lstm"]]
nombres = ["LR","DT","SVR","XGBR","RF","MLP","LSTM"]
pos=0
for i in my_data:
  print(nombres[pos],shapiro(i))
  pos=pos+1

"""***Intervalos de confianza para el error***"""

import scipy.stats as st
my_data = [metricslr["mse_lr"],metricsdt["mse_dt"],metricssvr["mse_svr"],metricsxgbr["mse_xgbr"],metricsrf["mse_rf"],metricsmlp["mse_mlp"],metricslstm["mse_lstm"]]
nombres = ["LR","DT","SVR","XGBR","RF","MLP","LSTM"]
pos=0
for i in my_data:
  print(nombres[pos],st.t.interval(alpha=0.95, df=len(i)-1, loc=np.mean(i), scale=st.sem(i)))
  pos=pos+1